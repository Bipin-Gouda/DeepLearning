{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKz3GiiVrQFkrXgz/+0uhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bipin-Gouda/DeepLearning/blob/main/PyTorchYT2%2C3_Autograd%2CBackpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd (does automatic gradience calculation in pytorch)"
      ],
      "metadata": {
        "id": "pRt_InNvMPkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1GEJu-XL_BA"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.randn(3, requires_grad=True)   #torch.rand_like()   # look\n",
        "print(x,x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXbZ4y9bOnBl",
        "outputId": "40e8085c-b248-4630-85c3-b2b230b7dec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1929, -0.2860,  2.6335], requires_grad=True) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `torch.rand()` is for Uniform distribution (in the half-open interval [0.0, 1.0))\n",
        "- `torch.randn()` is for Standard Normal (aka. Gaussian) distribution (mean 0 and variance 1)"
      ],
      "metadata": {
        "id": "vqQwqCcgSw1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if we are  calculating gradients of a function wrt tensor x then we must specify as requires_grad=True for tensor x"
      ],
      "metadata": {
        "id": "Po7v_eSiTBGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=x+2                   \n",
        "print(y)\n",
        "z=y*y*2\n",
        "print(z)\n",
        "z=z.mean()\n",
        "print(z)\n",
        "\n",
        "# here backward propagation is being used and gradient of y is calaulated wrt x ,\n",
        "# grad  of z calculated wrt x ( finally z depends on x) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLJgg4CQVhBd",
        "outputId": "ae201708-2e12-4dfc-aab3-551070278fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.1929, 1.7140, 4.6335], grad_fn=<AddBackward0>)\n",
            "tensor([ 9.6172,  5.8754, 42.9378], grad_fn=<MulBackward0>)\n",
            "tensor(19.4768, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()         # calculates gradient wrt x - dz/dx\n",
        "print(x.grad)        # prints gradients of this tensor\n",
        "\n",
        "# we can only get x.grad because z is a scalar value else we would have to enter a vector in z.backward()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpeoOpLzb1gT",
        "outputId": "fa1db089-fd01-45ce-9f89-9f0358926920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.9238, 2.2853, 6.1779])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Error if `requires_grad` not set to True\n",
        "- to get the gradients it does vector 'jacobian product' `(J.v, J= Jacobian matrix, v = vector)` to get the gradients (dz/dx)\n",
        "- Jacobian matrix is a matrix of partial derivatives. Jacobian is the determinant of the jacobian matrix. The matrix will contain all partial derivatives of a vector function. The main use of Jacobian is found in the transformation of coordinates. It deals with the concept of differentiation with coordinate transformation.\n",
        "- Note - Gradients help us to find the minima which we need for optimisation"
      ],
      "metadata": {
        "id": "V0OjDzv0YKZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=x+2                   \n",
        "print(y)\n",
        "z=y*y*2\n",
        "print(z)      #tensor([ 3.8336, 41.3203, 11.0452], grad_fn=<MulBackward0>)\n",
        "v=torch.tensor([0.1, 1.0,0.001], dtype=torch.float32)\n",
        "z.backward(v)     # as z is not a scalar we will need to enter a vector of same size as J.v  (jacobian matrix of z * vector v)\n",
        "print(x.grad)\n",
        "\n",
        "\n",
        "# most of time we will have scalar value as output so z.backward() will work noramlly else enter a vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGDeGT8vZmFH",
        "outputId": "28aa5e77-174e-4ad0-d377-d17c74eabafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.1929, 1.7140, 4.6335], grad_fn=<AddBackward0>)\n",
            "tensor([ 9.6172,  5.8754, 42.9378], grad_fn=<MulBackward0>)\n",
            "tensor([3.8010, 9.1412, 6.1965])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - whenever we call the `backward()` function the gradient of the tensor will be accumlated  in the `.grad` attribute ( the values wil be sumed up)"
      ],
      "metadata": {
        "id": "8O8oRKZExt-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to prevent PyTorch from tracking the history and calculating this `grad_fn=<AddBackward0>`, <MulBackward0> etc attribute when not required\n",
        "\n",
        "(eg when we need to update our weighs during our training loop and this operation (+-* either ) must not be a part of gradient computation"
      ],
      "metadata": {
        "id": "vV_nX4VkluTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 3 methods\n",
        "\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():"
      ],
      "metadata": {
        "id": "wFpctojCsxdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)   # note requires_grad=True not showing anymore in op"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQZMm-yOuSnF",
        "outputId": "ba525ddb-3838-4932-cb61-6f2aa14949ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1929, -0.2860,  2.6335])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)\n",
        "y=x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKptd4efusGR",
        "outputId": "f4b81dbd-289e-423a-fa56-710594969943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.1929, 1.7140, 4.6335], grad_fn=<AddBackward0>)\n",
            "tensor([ 0.1929, -0.2860,  2.6335])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  z=x+2\n",
        "  print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx_ri_RYvG1k",
        "outputId": "3d039fa3-4698-475c-8b41-ec16b5ce3088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.1929, 1.7140, 4.6335])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Tensor.detach()` method in PyTorch is used to separate a tensor from the computational graph by returning a new tensor that doesnâ€™t require a gradient. If we want to move a tensor from the Graphical Processing Unit (GPU) to the Central Processing Unit (CPU), then we can use detach() method. It will not take any parameter and return the detached tensor.\n",
        "- same with other two functions"
      ],
      "metadata": {
        "id": "9YUo5cd_sz-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE-  - whenever we call the `backward()` function the gradient of the tensor will be accumlated  in the `.grad` attribute ( the values wil be sumed up) eg-"
      ],
      "metadata": {
        "id": "IbooTOdQyHjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):                   # let a training loop\n",
        "\n",
        "  model_output= (weights*3).sum()        # just a dummy operation to simulate some model output \n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)                # values accumulated which can give wrong results\n",
        "\n",
        "  weights.grad.zero_()              # to set the gradients to zero before next iteration to prevent \n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqENDjFaxPoN",
        "outputId": "50ce68f7-c7ee-4637-a22b-a0378f821043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- we will look at optimizers later properly"
      ],
      "metadata": {
        "id": "gupMcG9h7mC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Trying inbuilt optimizers\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "weights2 = torch.ones(5, requires_grad=True)\n",
        "\n",
        "#cumu=[weights,weights2]\n",
        "\n",
        "optimizer = torch.optim.SGD(weights,lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()\n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "ZNcDs1rk7GiL",
        "outputId": "8314662d-543e-4b71-8ea0-0670e44b29a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5ee64130879a>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#cumu=[weights,weights2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[0m\u001b[1;32m    179\u001b[0m                             \u001b[0;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                             torch.typename(params))\n",
            "\u001b[0;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oLGHNvum8LBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BACKPROPAGATION"
      ],
      "metadata": {
        "id": "UjQi8xP9UzBq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFEe_83v8KNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}